{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import spatial\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_accuracy(actual, predicted):\n",
    "    true = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(actual)):\n",
    "        for j in range(i + 1, len(actual)):\n",
    "            total += 1\n",
    "\n",
    "            s1 = actual[i]\n",
    "            s2 = actual[j]\n",
    "            b1 = predicted[i]\n",
    "            b2 = predicted[j]\n",
    "\n",
    "            result1 = spatial.distance.cosine(s1, b1)\n",
    "            result2 = spatial.distance.cosine(s2, b2)\n",
    "            result3 = spatial.distance.cosine(s1, b2)\n",
    "            result4 = spatial.distance.cosine(s2, b1)\n",
    "\n",
    "            if result1 + result2 < result3 + result4:\n",
    "                true += 1\n",
    "\n",
    "    return true / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearcorr(actual, predicted):\n",
    "    corr = []\n",
    "    for i in range(0, len(actual)):\n",
    "        corr.append(np.corrcoef(actual[i], predicted[i])[0][1])\n",
    "    return np.mean(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices(data):\n",
    "    Taskindices = []\n",
    "    for j in data[\"meta\"][0][0][11][0][5]:\n",
    "        for k in j[0]:\n",
    "            Taskindices.append(int(k))\n",
    "    DMNindices = []\n",
    "    for j in data[\"meta\"][0][0][11][0][6]:\n",
    "        for k in j[0]:\n",
    "            DMNindices.append(int(k))\n",
    "    Visualindices = []\n",
    "    Visualindices_body = []\n",
    "    Visualindices_face = []\n",
    "    Visualindices_object = []\n",
    "    Visualindices_scene = []\n",
    "    for j in data[\"meta\"][0][0][11][0][9]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_body.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][10]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_face.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][11]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_object.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][12]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_scene.append(int(k))\n",
    "\n",
    "    for j in data[\"meta\"][0][0][11][0][13]:\n",
    "        for k in j[0]:\n",
    "            Visualindices.append(int(k))\n",
    "    Languageindices_lh = []\n",
    "    Languageindices_rh = []\n",
    "    for j in data[\"meta\"][0][0][11][0][7]:\n",
    "        for k in j[0]:\n",
    "            Languageindices_lh.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][8]:\n",
    "        for k in j[0]:\n",
    "            Languageindices_rh.append(int(k))\n",
    "    return (\n",
    "        Taskindices,\n",
    "        DMNindices,\n",
    "        Visualindices_body,\n",
    "        Visualindices_face,\n",
    "        Visualindices_object,\n",
    "        Visualindices_scene,\n",
    "        Visualindices,\n",
    "        Languageindices_lh,\n",
    "        Languageindices_rh,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\n",
    "    \"bert\",\n",
    "    \"coref\",\n",
    "    \"ner\",\n",
    "    \"nli\",\n",
    "    \"paraphrase\",\n",
    "    \"qa\",\n",
    "    \"sa\",\n",
    "    \"srl\",\n",
    "    \"ss\",\n",
    "    \"sum\",\n",
    "    \"wsd\",\n",
    "]\n",
    "ROIS = [\n",
    "    \"language_lh\",\n",
    "    \"language_rh\",\n",
    "    \"vision_body\",\n",
    "    \"vision_face\",\n",
    "    \"vision_object\",\n",
    "    \"vision_scene\",\n",
    "    \"vision\",\n",
    "    \"dmn\",\n",
    "    \"task\",\n",
    "]\n",
    "subjects = [\"P01\", \"M02\", \"M04\", \"M07\", \"M15\"]\n",
    "layers_bert = [\n",
    "    \"block1\",\n",
    "    \"block2\",\n",
    "    \"block3\",\n",
    "    \"block4\",\n",
    "    \"block5\",\n",
    "    \"block6\",\n",
    "    \"block7\",\n",
    "    \"block8\",\n",
    "    \"block9\",\n",
    "    \"block10\",\n",
    "    \"block11\",\n",
    "    \"block12\",\n",
    "    \"fc\",\n",
    "]\n",
    "layers_bart = [\"fc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data(subject):\n",
    "    data_pic1 = loadmat(\"./pereira_dataset/\" + subject + \"/data_384sentences.mat\")\n",
    "    data_pic2 = loadmat(\"./pereira_dataset/\" + subject + \"/data_243sentences.mat\")\n",
    "    data_pic = loadmat(\"./pereira_dataset/\" + subject + \"/data_384sentences.mat\")\n",
    "\n",
    "    data_pic[\"examples_passagesentences\"] = np.concatenate(\n",
    "        (\n",
    "            data_pic1[\"examples_passagesentences\"],\n",
    "            data_pic2[\"examples_passagesentences\"],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    data_pic[\"meta\"] = np.concatenate((data_pic1[\"meta\"], data_pic2[\"meta\"]), axis=0)\n",
    "    (\n",
    "        Taskindices,\n",
    "        DMNindices,\n",
    "        Visualindices_body,\n",
    "        Visualindices_face,\n",
    "        Visualindices_object,\n",
    "        Visualindices_scene,\n",
    "        Visualindices,\n",
    "        Languageindices_lh,\n",
    "        Languageindices_rh,\n",
    "    ) = generate_indices(data_pic)\n",
    "\n",
    "    roi_indices = {\n",
    "        \"language_lh\": Languageindices_lh,\n",
    "        \"language_rh\": Languageindices_rh,\n",
    "        \"vision_body\": Visualindices_body,\n",
    "        \"vision_face\": Visualindices_face,\n",
    "        \"vision_object\": Visualindices_object,\n",
    "        \"vision_scene\": Visualindices_scene,\n",
    "        \"vision\": Visualindices,\n",
    "        \"dmn\": DMNindices,\n",
    "        \"task\": Taskindices,\n",
    "    }\n",
    "\n",
    "    fmri = {}\n",
    "    for roi, indices in roi_indices.items():\n",
    "        fmri[roi] = data_pic[\"examples_passagesentences\"][0:, np.array(indices) - 1]\n",
    "\n",
    "    return fmri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.w = torch.nn.Parameter(torch.randn(11, 1))\n",
    "\n",
    "    def forward(self, model_outputs, x):\n",
    "        model_outputs = model_outputs.permute(0, 2, 1)\n",
    "        weights = self.w**2\n",
    "        weights = weights / weights.sum()\n",
    "        weighted_embedding = (model_outputs @ weights).squeeze()\n",
    "        loss = torch.nn.functional.mse_loss(weighted_embedding, x)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Custom_Dataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(X_train, y_train):\n",
    "    train_dataset = Custom_Dataset(X_train, y_train)\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=True, num_workers=6\n",
    "    )\n",
    "\n",
    "    EPOCHS = 100\n",
    "    model = Net()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        losses = []\n",
    "        for X, y in train_dataloader:\n",
    "            loss = model(X.float(), y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        mean_loss = np.mean(losses)\n",
    "\n",
    "    weights = model.w.detach().numpy().squeeze()\n",
    "    weights = weights**2\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    del train_dataset, train_dataloader, model, optimizer, losses, mean_loss\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def create_ensemble(outputs, voxels):\n",
    "    outputs = outputs.transpose(1, 0, 2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        outputs, voxels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    weights = get_weights(X_train, y_train)\n",
    "\n",
    "    X_test = X_test.transpose(0, 2, 1)\n",
    "    y_pred = X_test @ weights\n",
    "    acc = pairwise_accuracy(y_test, y_pred)\n",
    "    corr = pearcorr(y_test, y_pred)\n",
    "    del X_train, X_test, y_train, y_test, y_pred\n",
    "\n",
    "    return acc, corr, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "output[\"2v2\"] = {}\n",
    "output[\"pear\"] = {}\n",
    "output[\"weights\"] = {}\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "    output[\"2v2\"][subject] = {}\n",
    "    output[\"pear\"][subject] = {}\n",
    "    output[\"weights\"][subject] = {}\n",
    "    fmri = get_subject_data(subject)\n",
    "\n",
    "    for roi in ROIS:\n",
    "        print(f\"{subject} {roi}\")\n",
    "        model_outputs = []\n",
    "        voxels = np.array(fmri[roi])\n",
    "\n",
    "        for task in TASKS:\n",
    "            data = np.load(f\"./features/pereira_{task}.npy\", allow_pickle=True)\n",
    "            feats = np.array(data[-1])\n",
    "            with open(f\"./models/{task}_{roi}_{subject}.model\", \"rb\") as f:\n",
    "                model = pickle.load(f)\n",
    "\n",
    "            model_output = model.predict(feats)\n",
    "            model_outputs.append(model_output)\n",
    "            del model, data, feats, model_output\n",
    "\n",
    "        model_outputs = np.array(model_outputs)\n",
    "        acc, corr, weights = create_ensemble(model_outputs, voxels)\n",
    "        output[\"2v2\"][subject][roi] = acc\n",
    "        output[\"pear\"][subject][roi] = corr\n",
    "        output[\"weights\"][subject][roi] = weights\n",
    "        del model_outputs, voxels\n",
    "\n",
    "    del fmri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_output = {}\n",
    "ensemble_output[\"2v2\"] = {}\n",
    "ensemble_output[\"pear\"] = {}\n",
    "ensemble_output[\"weights\"] = {}\n",
    "for roi in ROIS:\n",
    "    ensemble_output[\"2v2\"][roi] = {}\n",
    "    ensemble_output[\"pear\"][roi] = {}\n",
    "    ensemble_output[\"weights\"][roi] = {}\n",
    "    for subject in subjects:\n",
    "        ensemble_output[\"2v2\"][roi][subject] = output[\"2v2\"][subject][roi]\n",
    "        ensemble_output[\"pear\"][roi][subject] = output[\"pear\"][subject][roi]\n",
    "        ensemble_output[\"weights\"][roi][subject] = output[\"weights\"][subject][roi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/results_ensemble_dyn_wt.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ensemble_output, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
