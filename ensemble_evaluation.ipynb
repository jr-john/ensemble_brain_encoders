{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle load the file ensemble.pkl\n",
    "with open(\"ensemble_wt_avg.pkl\", \"rb\") as f:\n",
    "    ensemble = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_accuracy(actual, predicted):\n",
    "    true = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(actual)):\n",
    "        for j in range(i + 1, len(actual)):\n",
    "            total += 1\n",
    "\n",
    "            s1 = actual[i]\n",
    "            s2 = actual[j]\n",
    "            b1 = predicted[i]\n",
    "            b2 = predicted[j]\n",
    "\n",
    "            result1 = spatial.distance.cosine(s1, b1)\n",
    "            result2 = spatial.distance.cosine(s2, b2)\n",
    "            result3 = spatial.distance.cosine(s1, b2)\n",
    "            result4 = spatial.distance.cosine(s2, b1)\n",
    "\n",
    "            if result1 + result2 < result3 + result4:\n",
    "                true += 1\n",
    "\n",
    "    return true / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearcorr(actual, predicted):\n",
    "    corr = []\n",
    "    for i in range(0, len(actual)):\n",
    "        corr.append(np.corrcoef(actual[i], predicted[i])[0][1])\n",
    "    return np.mean(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices(data):\n",
    "    Taskindices = []\n",
    "    for j in data[\"meta\"][0][0][11][0][5]:\n",
    "        for k in j[0]:\n",
    "            Taskindices.append(int(k))\n",
    "    DMNindices = []\n",
    "    for j in data[\"meta\"][0][0][11][0][6]:\n",
    "        for k in j[0]:\n",
    "            DMNindices.append(int(k))\n",
    "    Visualindices = []\n",
    "    Visualindices_body = []\n",
    "    Visualindices_face = []\n",
    "    Visualindices_object = []\n",
    "    Visualindices_scene = []\n",
    "    for j in data[\"meta\"][0][0][11][0][9]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_body.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][10]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_face.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][11]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_object.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][12]:\n",
    "        for k in j[0]:\n",
    "            Visualindices_scene.append(int(k))\n",
    "\n",
    "    for j in data[\"meta\"][0][0][11][0][13]:\n",
    "        for k in j[0]:\n",
    "            Visualindices.append(int(k))\n",
    "    Languageindices_lh = []\n",
    "    Languageindices_rh = []\n",
    "    for j in data[\"meta\"][0][0][11][0][7]:\n",
    "        for k in j[0]:\n",
    "            Languageindices_lh.append(int(k))\n",
    "    for j in data[\"meta\"][0][0][11][0][8]:\n",
    "        for k in j[0]:\n",
    "            Languageindices_rh.append(int(k))\n",
    "    return (\n",
    "        Taskindices,\n",
    "        DMNindices,\n",
    "        Visualindices_body,\n",
    "        Visualindices_face,\n",
    "        Visualindices_object,\n",
    "        Visualindices_scene,\n",
    "        Visualindices,\n",
    "        Languageindices_lh,\n",
    "        Languageindices_rh,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIS = [\n",
    "    \"language_lh\",\n",
    "    \"language_rh\",\n",
    "    \"vision_body\",\n",
    "    \"vision_face\",\n",
    "    \"vision_object\",\n",
    "    \"vision_scene\",\n",
    "    \"vision\",\n",
    "    \"dmn\",\n",
    "    \"task\",\n",
    "]\n",
    "subjects = [\"P01\", \"M02\", \"M04\", \"M07\", \"M15\"]\n",
    "layers_bert = [\n",
    "    \"block1\",\n",
    "    \"block2\",\n",
    "    \"block3\",\n",
    "    \"block4\",\n",
    "    \"block5\",\n",
    "    \"block6\",\n",
    "    \"block7\",\n",
    "    \"block8\",\n",
    "    \"block9\",\n",
    "    \"block10\",\n",
    "    \"block11\",\n",
    "    \"block12\",\n",
    "    \"fc\",\n",
    "]\n",
    "layers_bart = [\"fc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_data(subject):\n",
    "    data_pic1 = loadmat(\"./pereira_dataset/\" + subject + \"/data_384sentences.mat\")\n",
    "    data_pic2 = loadmat(\"./pereira_dataset/\" + subject + \"/data_243sentences.mat\")\n",
    "    data_pic = loadmat(\"./pereira_dataset/\" + subject + \"/data_384sentences.mat\")\n",
    "\n",
    "    data_pic[\"examples_passagesentences\"] = np.concatenate(\n",
    "        (\n",
    "            data_pic1[\"examples_passagesentences\"],\n",
    "            data_pic2[\"examples_passagesentences\"],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    data_pic[\"meta\"] = np.concatenate((data_pic1[\"meta\"], data_pic2[\"meta\"]), axis=0)\n",
    "    (\n",
    "        Taskindices,\n",
    "        DMNindices,\n",
    "        Visualindices_body,\n",
    "        Visualindices_face,\n",
    "        Visualindices_object,\n",
    "        Visualindices_scene,\n",
    "        Visualindices,\n",
    "        Languageindices_lh,\n",
    "        Languageindices_rh,\n",
    "    ) = generate_indices(data_pic)\n",
    "\n",
    "    roi_indices = {\n",
    "        \"language_lh\": Languageindices_lh,\n",
    "        \"language_rh\": Languageindices_rh,\n",
    "        \"vision_body\": Visualindices_body,\n",
    "        \"vision_face\": Visualindices_face,\n",
    "        \"vision_object\": Visualindices_object,\n",
    "        \"vision_scene\": Visualindices_scene,\n",
    "        \"vision\": Visualindices,\n",
    "        \"dmn\": DMNindices,\n",
    "        \"task\": Taskindices,\n",
    "    }\n",
    "\n",
    "    fmri = {}\n",
    "    for roi, indices in roi_indices.items():\n",
    "        fmri[roi] = data_pic[\"examples_passagesentences\"][0:, np.array(indices) - 1]\n",
    "\n",
    "    return fmri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y, roi, subject):\n",
    "    dataset_Y = np.array(Y.copy())\n",
    "    _, y_test, _, y_pred = train_test_split(\n",
    "        dataset_Y, ensemble[subject][roi], test_size=0.2, random_state=42\n",
    "    )\n",
    "    acc = pairwise_accuracy(y_test, y_pred)\n",
    "    corr = pearcorr(y_test, y_pred)\n",
    "\n",
    "    return acc, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "output[\"2v2\"] = {}\n",
    "output[\"pear\"] = {}\n",
    "\n",
    "for roi in ROIS:\n",
    "    print(roi)\n",
    "    output[\"2v2\"][roi] = {}\n",
    "    output[\"pear\"][roi] = {}\n",
    "\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        fmri = get_subject_data(subject)\n",
    "        voxels = np.array(fmri[roi])\n",
    "        acc, corr = evaluate(voxels, roi, subject)\n",
    "        output[\"2v2\"][roi][subject] = acc\n",
    "        output[\"pear\"][roi][subject] = corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/results_ensemble_wt_avg.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
